# üöÄ Quick Start Guide

H∆∞·ªõng d·∫´n nhanh ƒë·ªÉ b·∫Øt ƒë·∫ßu v·ªõi DOVE-SkyScripts trong 5 ph√∫t.

---

## ‚ö° Setup nhanh (5 ph√∫t)

### 1. Clone v√† c√†i ƒë·∫∑t (2 ph√∫t)

```bash
# Clone repository
git clone https://github.com/AlanKhan145/Dove-SkyScripts.git
cd Dove-SkyScripts

# T·∫°o m√¥i tr∆∞·ªùng
conda create -n dove python=3.9 -y
conda activate dove

# C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt

# C√†i PyTorch (CUDA 11.8)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 2. Download dataset (2 ph√∫t)

```bash
# Download v√† unzip SkyScript dataset
bash download_skyscript.sh
bash unzip_skyscript.sh
```

### 3. Test installation (1 ph√∫t)

```python
# test_install.py
import torch
import torchvision
print(f"‚úÖ PyTorch version: {torch.__version__}")
print(f"‚úÖ CUDA available: {torch.cuda.is_available()}")
print(f"‚úÖ Installation successful!")
```

```bash
python test_install.py
```

---

## üéØ Use Cases

### Case 1: Training t·ª´ ƒë·∫ßu

```bash
# Training with default settings
python train_dove.py \
    --data_root "data/images" \
    --train_csv "data/dataframe/SkyScript_train_top50pct_filtered_by_CLIP_openai.csv" \
    --val_csv "data/dataframe/SkyScript_val_5K_filtered_by_CLIP_openai.csv" \
    --out_dir "runs/my_first_model"
```

**Th·ªùi gian**: ~8-10 gi·ªù tr√™n 1 GPU A100 (20 epochs)

### Case 2: Evaluation v·ªõi pretrained model

```bash
# Download pretrained checkpoint
wget https://example.com/dove_pretrained.pt -O checkpoints/dove_pretrained.pt

# Evaluate
python eval_retrieval.py \
    --data_root "data/images" \
    --csv "data/dataframe/SkyScript_test_30K_filtered_by_CLIP_openai.csv" \
    --ckpt "checkpoints/dove_pretrained.pt"
```

**Th·ªùi gian**: ~30 ph√∫t

### Case 3: Demo v·ªõi Jupyter Notebook

```bash
# Start Jupyter
jupyter notebook demo_dove_retrieval.ipynb
```

Trong notebook:
1. Load model
2. Upload ·∫£nh c·ªßa b·∫°n
3. Xem top-k similar images/texts
4. Visualize attention maps

---

## üéì Training Examples

### Example 1: Fast training (cho testing)

```bash
python train_dove.py \
    --data_root "data/images" \
    --train_csv "data/dataframe/SkyScript_train_top50pct_filtered_by_CLIP_openai.csv" \
    --val_csv "data/dataframe/SkyScript_val_5K_filtered_by_CLIP_openai.csv" \
    --batch_size 128 \
    --epochs 5 \
    --lr 5e-4 \
    --out_dir "runs/fast_test"
```

**∆Øu ƒëi·ªÉm**: Nhanh, ph√π h·ª£p ƒë·ªÉ test code
**Nh∆∞·ª£c ƒëi·ªÉm**: Accuracy th·∫•p h∆°n

### Example 2: Production training (recommended)

```bash
python train_dove.py \
    --data_root "data/images" \
    --train_csv "data/dataframe/SkyScript_train_top50pct_filtered_by_CLIP_openai.csv" \
    --val_csv "data/dataframe/SkyScript_val_5K_filtered_by_CLIP_openai.csv" \
    --caption_field "title_multi_objects" \
    --batch_size 64 \
    --epochs 20 \
    --lr 2e-4 \
    --embed_dim 512 \
    --lambda_g 10.0 \
    --amp 1 \
    --out_dir "runs/production"
```

**∆Øu ƒëi·ªÉm**: SOTA results
**Nh∆∞·ª£c ƒëi·ªÉm**: M·∫•t th·ªùi gian

### Example 3: Multi-GPU training

```bash
# 4 GPUs
torchrun --nproc_per_node=4 train_dove.py \
    --data_root "data/images" \
    --train_csv "data/dataframe/SkyScript_train_top50pct_filtered_by_CLIP_openai.csv" \
    --val_csv "data/dataframe/SkyScript_val_5K_filtered_by_CLIP_openai.csv" \
    --batch_size 128 \
    --epochs 20 \
    --out_dir "runs/distributed"
```

**∆Øu ƒëi·ªÉm**: Nhanh g·∫•p 4 l·∫ßn
**Y√™u c·∫ßu**: 4 GPUs

---

## üìä Expected Results

### Training Progress

Sau 20 epochs, b·∫°n s·∫Ω th·∫•y:

```
Epoch 20/20
‚îú‚îÄ‚îÄ Train Loss: 0.15
‚îú‚îÄ‚îÄ Val Loss: 0.18
‚îú‚îÄ‚îÄ Image‚ÜíText R@1: 17.04%
‚îú‚îÄ‚îÄ Image‚ÜíText R@5: 39.60%
‚îú‚îÄ‚îÄ Text‚ÜíImage R@1: 13.63%
‚îî‚îÄ‚îÄ Text‚ÜíImage R@5: 45.27%
```

### Evaluation Metrics

```
Cross-Modal Retrieval Results:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Metric              ‚îÇ Value          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Image‚ÜíText R@1      ‚îÇ 17.04%         ‚îÇ
‚îÇ Image‚ÜíText R@5      ‚îÇ 39.60%         ‚îÇ
‚îÇ Image‚ÜíText R@10     ‚îÇ 50.88%         ‚îÇ
‚îÇ Text‚ÜíImage R@1      ‚îÇ 13.63%         ‚îÇ
‚îÇ Text‚ÜíImage R@5      ‚îÇ 45.27%         ‚îÇ
‚îÇ Text‚ÜíImage R@10     ‚îÇ 66.11%         ‚îÇ
‚îÇ Mean Recall (mR)    ‚îÇ 38.75%         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Common Issues

### Issue 1: CUDA Out of Memory

**Tri·ªáu ch·ª©ng**: `RuntimeError: CUDA out of memory`

**Gi·∫£i ph√°p**:
```bash
# Gi·∫£m batch size
python train_dove.py --batch_size 32  # thay v√¨ 64

# Ho·∫∑c gi·∫£m image size
python train_dove.py --image_size 224  # thay v√¨ 256

# Ho·∫∑c s·ª≠ d·ª•ng gradient accumulation
python train_dove.py --batch_size 32 --accumulation_steps 2
```

### Issue 2: Slow training

**Tri·ªáu ch·ª©ng**: Qu√° ch·∫≠m, 1 epoch m·∫•t > 2 gi·ªù

**Gi·∫£i ph√°p**:
```bash
# B·∫≠t mixed precision training
python train_dove.py --amp 1

# TƒÉng num_workers
python train_dove.py --num_workers 8

# S·ª≠ d·ª•ng smaller dataset
python train_dove.py --train_csv "data/dataframe/SkyScript_train_top30pct_filtered_by_CLIP_openai.csv"
```

### Issue 3: Low accuracy

**Tri·ªáu ch·ª©ng**: Accuracy < 50% sau training

**Checklist**:
- [ ] ƒê√£ d√πng ƒë√∫ng pretrained ResNet-50 on AID?
- [ ] ƒê√£ set `caption_field = "title_multi_objects"`?
- [ ] ƒê√£ set `lambda_g = 10.0`?
- [ ] ƒê√£ train ƒë·ªß 20 epochs?
- [ ] Learning rate ph√π h·ª£p (2e-4)?

---

## üí° Tips & Tricks

### Tip 1: S·ª≠ d·ª•ng wandb ƒë·ªÉ track experiments

```python
# Trong train_dove.py, th√™m:
import wandb

wandb.init(
    project="dove-skyscripts",
    config={
        "learning_rate": args.lr,
        "epochs": args.epochs,
        "batch_size": args.batch_size
    }
)

# Log metrics
wandb.log({"train_loss": loss, "val_loss": val_loss})
```

### Tip 2: Early stopping

```python
# Th√™m v√†o training loop:
best_val_loss = float('inf')
patience = 5
patience_counter = 0

for epoch in range(epochs):
    val_loss = validate()
    
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        save_checkpoint()
    else:
        patience_counter += 1
        
    if patience_counter >= patience:
        print("Early stopping!")
        break
```

### Tip 3: Learning rate scheduling

```python
from torch.optim.lr_scheduler import CosineAnnealingLR

scheduler = CosineAnnealingLR(optimizer, T_max=epochs)

for epoch in range(epochs):
    train()
    validate()
    scheduler.step()
```

---

## üìö Next Steps

Sau khi ho√†n th√†nh Quick Start:

1. **ƒê·ªçc full README**: [README.md](README.md)
2. **Xem chi ti·∫øt Architecture**: [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)
3. **T√¨m hi·ªÉu Dataset**: [docs/DATASET.md](docs/DATASET.md)
4. **Advanced Training**: [docs/TRAINING.md](docs/TRAINING.md)
5. **Deploy model**: [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)

---

## üÜò Getting Help

- **Quick questions**: [GitHub Discussions](https://github.com/AlanKhan145/Dove-SkyScripts/discussions)
- **Bug reports**: [GitHub Issues](https://github.com/AlanKhan145/Dove-SkyScripts/issues)
- **Email**: your-email@example.com

---

**Happy coding! üöÄ**
